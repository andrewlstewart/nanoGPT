{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anstewart/src/nanoGPT/venv_py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, C = 4, 8, 32  # Batch = block of text, Time = Token, C = Latent dimension of embedded token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "t=45m\n",
    "If you want to give the current token some information from all prior tokens, a weak information algo could\n",
    "be just to average the current, and all previous token embeddings\n",
    "\"\"\"\n",
    "x_bag_of_words = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b, :t+1]\n",
    "        x_bag_of_words[b, t] = torch.mean(x_prev, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "t=48m\n",
    "matmul\n",
    "\"\"\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, dim=1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,2)).float()\n",
    "c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000, 7.0000],\n",
       "        [4.0000, 5.5000],\n",
       "        [4.6667, 5.3333]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / weights.sum(1, keepdim=True)  # [T, T]\n",
    "x_bag_of_words_2 = weights @ x  # [T, T] @ [B, T, C]  -> [B, T, T] @ [B, T, C] <- auto broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8227, -1.1273,  1.5287,  0.6238, -0.8932,  0.8044,  0.0726, -1.0536,\n",
       "          0.1823,  0.4875, -0.6720, -1.6526, -0.8162,  0.4470, -0.4603, -0.2107,\n",
       "         -0.0129, -1.1054,  0.5221,  0.7951,  1.0665, -2.1980, -0.6582, -0.4577,\n",
       "         -1.1629,  0.9793, -1.8782, -0.3928,  1.3737,  0.9752,  1.0107, -0.6734],\n",
       "        [-1.7003, -0.9309,  0.1334, -0.0312, -0.2632, -0.0542,  0.4349,  0.1707,\n",
       "          0.4232, -0.3119, -0.6285, -0.6307, -0.9627,  0.0278, -0.0460,  0.0322,\n",
       "          0.4694, -1.5157,  0.5696,  0.5325,  0.3490, -0.8446, -0.6399, -0.5391,\n",
       "         -0.6487,  0.6789, -0.5102, -1.2916,  0.6075, -0.0218,  0.9780,  1.0115],\n",
       "        [-1.0051, -0.4442, -0.3487, -0.0123, -0.2081,  0.1498,  0.2510, -0.1040,\n",
       "          0.0475,  0.3782, -0.3582,  0.0159, -0.7279,  0.3315, -0.3390, -0.4231,\n",
       "          0.4025, -1.1518,  0.4305,  0.2544, -0.3452, -0.4493, -0.5750, -0.2918,\n",
       "         -0.5466,  0.4084, -0.6851, -0.9648,  1.1235,  0.0195,  0.0843,  0.5277],\n",
       "        [-0.7769, -0.3613, -0.5125, -0.0314, -0.4595,  0.1575,  0.1793,  0.4839,\n",
       "         -0.4766,  0.1564, -0.3238,  0.1711, -0.5634,  0.2304,  0.1815, -0.5288,\n",
       "          0.4229, -0.9759,  0.3477, -0.0467, -0.3405, -0.3500, -0.1497, -0.0552,\n",
       "         -0.1450,  0.7957, -0.1526, -1.1213,  0.7199, -0.0068,  0.4549, -0.1044],\n",
       "        [-0.8393,  0.0105, -0.4896, -0.1955, -0.3243, -0.2825,  0.1597,  0.3298,\n",
       "         -0.6091,  0.2823, -0.0625,  0.0224, -0.7382,  0.0505,  0.2211, -0.0688,\n",
       "          0.2866, -1.0580,  0.3445, -0.2378, -0.0632, -0.0941, -0.2626, -0.1488,\n",
       "         -0.4037,  0.6198, -0.2701, -1.0374,  0.4852, -0.0520,  0.2931, -0.3060],\n",
       "        [-0.8817,  0.0769, -0.4413, -0.0726, -0.3169, -0.3067,  0.4181,  0.1833,\n",
       "         -0.2445,  0.2844, -0.0817,  0.0936, -0.6450,  0.1333,  0.3312, -0.1116,\n",
       "          0.1208, -1.1989,  0.3564, -0.0091,  0.0779, -0.2754, -0.1615, -0.2108,\n",
       "         -0.3616,  0.7137, -0.2852, -0.5740,  0.4880, -0.1407,  0.2646, -0.4238],\n",
       "        [-0.7375,  0.0410, -0.4261, -0.0912, -0.4038, -0.1138,  0.3989,  0.0769,\n",
       "         -0.1102,  0.0750, -0.2163,  0.0474, -0.3019,  0.3092,  0.4100, -0.1001,\n",
       "          0.1102, -0.8882,  0.0902,  0.1297,  0.1210, -0.3995,  0.0043, -0.0314,\n",
       "         -0.4119,  0.6659, -0.2822, -0.3173,  0.6691,  0.1779,  0.0680, -0.3537],\n",
       "        [-0.6424,  0.0752, -0.2255, -0.1104, -0.4143, -0.1534,  0.4548,  0.0754,\n",
       "         -0.0688,  0.1662, -0.0130, -0.0294, -0.2824,  0.4619,  0.2656, -0.1328,\n",
       "          0.2351, -1.1276,  0.1176,  0.1896,  0.0674, -0.1339, -0.0242, -0.0211,\n",
       "         -0.3195,  0.7583, -0.3019, -0.4557,  0.5460,  0.1610,  0.3494, -0.2557]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_bag_of_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(x_bag_of_words, x_bag_of_words_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "56m\n",
    "softmax\n",
    "\"\"\"\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))  # Wherever the lower diagonal is zero, set to -inf\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "x_bag_of_words_3 = weights @ x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(x_bag_of_words, x_bag_of_words_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEach embedded token vector generates its own key and query vector (k & q)\\nNo information has been shared between tokens yet\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "1hr5min\n",
    "\"\"\"\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32  # batch, time, channels\n",
    "x = torch.rand(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = torch.nn.Linear(C, head_size, bias=False)  # -> x [B, T, C] @ W [C, h] (matrix multiplication) -> [B, T, h]\n",
    "query = torch.nn.Linear(C, head_size, bias=False)\n",
    "value = torch.nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "\"\"\"\n",
    "Each embedded token vector generates its own key and query vector (k & q)\n",
    "No information has been shared between tokens yet\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1hr6m13s\n",
    "This computes the affinity by dot producting the query and key matricies\n",
    "    IE each embedding token query vector gets multiplied by every other (and it's own) embedded token key vector\n",
    "Element B,0,0 is query row 0 dotted with key row 0 (what info does the first token relate to itself)\n",
    "Element B,1,0 is query row 1 dotted with key row 0 (what info does the second token relate to the first token)\n",
    "\"\"\"\n",
    "weights = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) -> (B, T, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove the communication to future tokens\n",
    "\"\"\"\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weights = weights.masked_fill(tril==0, float('-inf'))\n",
    "\"\"\"\n",
    "The softmax happens AFTER setting future token information to -inf, therefore even though the communication has happened\n",
    "No information in the final weights matrix is introduced during the softmax\n",
    "\"\"\"\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "v = value(x)\n",
    "out = weights @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8286a41151f862bf239cdf8d3741ec4df4beda63d7e252051dff80ae23a157f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
